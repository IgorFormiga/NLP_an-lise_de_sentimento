{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste projeto é a criação de um modelo de Machine Learning de classificação utilizado o processamento de linguagem natural. O modelo irá classificar os comentários em três classes: \"Positivo\", \"Negativo\" e \"Neutro\". O conjunto de comentários negativos possui um alto valor de informação para empresas, podendo ser utilizado como feedback de melhoria e/ou base de dados para análise de causa raiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import tokenize, RSLPStemmer, FreqDist, tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.lm import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "from string import punctuation\n",
    "from time import time\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from utils.regex_utils import *\n",
    "from utils.stopword_utils import RemoverStopwords\n",
    "from utils.normalize_utils import ProcessoNormalizacao\n",
    "from utils.stemming_utils import ProcessoStemming\n",
    "from utils.features_extract import ExtracaoFeatures, E2V_IDF\n",
    "from utils.n_grams_utils import ngrams_count\n",
    "from utils.wordcloud_utils import nuvem_palavras\n",
    "from utils.select_model_utils import print_score_BayesSearchCV, print_score\n",
    "from utils.word2vec_utils import E2V_IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Leitura dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto foi desenvolvido utilizado um conjunto de dados público de e-commerce brasileiro de pedidos feitos na Olist Store, a maior loja de departamentos dos marketplaces brasileiros. A Olist conecta pequenas empresas de todo o Brasil a canais sem complicações e com um único contrato. Esses comerciantes podem vender seus produtos através da Olist Store e enviá-los diretamente aos clientes usando os parceiros de logística da Olist. O dataset possui informações de 100 mil pedidos de 2016 a 2018 feitos em vários marketplaces no Brasil. \n",
    "\n",
    "A base de dados de reviews foi construída a partir compras de produtos por clientes na Olist Store. Assim que o cliente recebe o produto, ou vence a data prevista de entrega, o cliente recebe uma pesquisa de satisfação por e-mail onde pode dar uma nota da experiência de compra e anotar alguns comentários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('order_reviews.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compreensão de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Analise de dados faltantes (Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['review_id', 'review_creation_date', 'review_answer_timestamp', 'review_comment_title', 'order_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_score            99224 non-null  int64 \n",
      " 1   review_comment_message  40977 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40977, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retirando o valores Null de reviews\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_score                             review_comment_message\n",
       "0             5              Recebi bem antes do prazo estipulado.\n",
       "1             5  Parabéns lojas lannister adorei comprar pela I...\n",
       "2             4  aparelho eficiente. no site a marca do aparelh...\n",
       "3             4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "4             5  Vendedor confiável, produto ok e entrega antes..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Rotulagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando um datafrem que contem as quantidade de acordo com o score\n",
    "quantidade = pd.DataFrame(dataset['review_score'].value_counts()).sort_index()\n",
    "\n",
    "# plotando o gráfico de barra\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.barplot(y='review_score', x=quantidade.index, data=quantidade, orient='v', palette='viridis')\n",
    "ax.set_title('Quantidade de comentários por score', fontdict={'fontsize': 20})\n",
    "ax.set(ylabel=None, xlabel=None)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com objetivo de criar um modelo de análise sentimental em uma abordagem de Machine Learning supervisionado, iremos dividir os sentimentos em três classes: negativo, neutro e positivo. O database não possui uma definição explicita sobre a definição de sentimento para cada comentário. Pensando em uma implementação rápida, utilizaremos a coluna \"review_score\" para rotular os dados nas três classes já que ela dá uma uma ideia sobre a satisfação do cliente a respeito da compra.\n",
    "\n",
    "Rotulagem dos dados:\n",
    "- Positivo (1): Compreende os scores de valores 4 e 5\n",
    "- Neutro (0): Compreende o score de valor 3\n",
    "- Negativo (-1): Compreende os scores de valores 1 e 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotulagem dos dados\n",
    "score_map = {\n",
    "    1: -1,\n",
    "    2: -1,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 1\n",
    "}\n",
    "\n",
    "dataset['sentiment_label'] = dataset['review_score'].map(score_map)\n",
    "dataset = dataset[['review_score', 'sentiment_label','review_comment_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_score  sentiment_label  \\\n",
       "0             5                1   \n",
       "1             5                1   \n",
       "2             4                1   \n",
       "3             4                1   \n",
       "4             5                1   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    26530\n",
       "-1    10890\n",
       " 0     3557\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAFUCAYAAAAAtgZ5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsaUlEQVR4nO3dd5wkRf3G8c8XjijhyEFAEITDQBqkRbIiQzAAogjSgpjJs4DyA3VmBAVF+gARFUGEFRUEExIGlAwy4pAOYUBBUImSBCQe1O+P6j3m1t293bvZqe7p5/167Yu7up2dZxWeq63urjLnHCIikn3zhQ4gIiLjo8IWEckJFbaISE6osEVEckKFLSKSEypsEZGcUGGLiOSECltEJCdU2CIiOaHCFhHJCRW2iEhOqLBFRHJChS0ikhMqbBGRnFBhi4jkhApbRCQnVNgiIjmhwhYRyQkVtohITqiwRURyQoUtIpITKmwRkZwobGGb2atmdquZ3WFmvzCzRSf4+pXN7Pz01xuY2Y4df/ZBMzui25lFpNjMORc6QxBm9pxzbrH01+cALedcMpdfax9gY+fcAV2MKCIym8LOsIe5FljLzJY2s1+b2e1mdqOZrQdgZluls/FbzewWM1vczFZPZ+cLAl8Ddk//fHcz28fMTjGzJc3sfjObL/06i5rZP81sgXRWfmP6Xr8ys6UCfv8ikgOFL2wzmwLsAMwA6sAtzrn1gCOBs9NPOwzY3zm3AbAF8MLQ651zLwNfBc51zm3gnDu348/+A9wGbJUOfQBoOOdeSb/2l9L3mgFUJ+2bFJG+UOTCXsTMbgX+DPwDOAPYHBgEcM5dASxjZksC1wOJmR0ETHXOzZzA+5wL7J7++mPAuenXnOqcuzodPwvYch6/HxHpc1NCBwjohXTGPIuZ2Qif55xzx5nZRcCOwI1mti3w4jjf57fAsWa2NFACrgAWm/vYIlJURZ5hj+Qa4OMAZrY18Lhz7hkzW9M5N8M59038jHzasNc9Cyw+0hd0zj0H/Ak4Cfidc+7VdKnkKTPbIv20GLh6pNeLiAwp8gx7JDXgTDO7HXge2DsdP8TMtgFeBe4ELgFW6njdlcAR6RLLsSN83XOBXwBbd4ztDXw/vZ3wPuCTXfsuRKQvFfa2PhGRvNGSiIhITqiwRURyQoUtIpITKuzAzGyqmZ1vZm0zu8vMNjWzmpk92PF05Y7p526WPhl5k5mt1fH6xii3JIpIH9FFx8DM7CzgWufc6elj7osChwDPOee+Pexzfwl8CVgd2N45d6iZnQD8tuMhnL5QLlXnAxbo+JgCzAReaLTq470HXqSv6La+gMxsCfwTjvvArMfcXx5jsvwKsAi+1F8xszWBN2a5rMul6vz4v2DWAJYHluv4Z+fHMsDC+H8nF2CMn/7KpaoDXgKeA55JP/4DPAE8CPxr+EejVX+569+cSI9phh2QmW0AnIa/t3t9oAUcDByOL/Fn8A/qHOqceyr9/O/j9zKJgW8DX3HO/bXX2Ycrl6qrAGunH2/p+Oeb8QUckgMeBx4A/oLfu2UGcEejVX8oZDCRiVBhB2RmGwM3Aps555pmdhK+pE/BF4wDjgZWcs7tO+y1WwI74wv8aPzs+1Dn3KOTnbtcqi4LRMAm6cc78TPkPHoCuCP9uA24Abiz0arrPwzJHBV2QGa2InCjc2719PdbAEc453bq+JzV8Y+0v71jzIAGflOpU/CFvTqwhXPuqG5mLJeqBmyI33FwqKTX6OZ7ZNATwHX4rQquAW5ptOqvho0kojXsoJxzj6T7Y6/jnLsbeC9wp5mt5Jx7OP20XfCzv057AxelyySLAq+lHxM6NWc05VJ1OaCcfmyHX3MukmWAD6UfAM+WS9U/4vd7uajRqt8WLJkUmmbYgaXr0qcDC/L6niInAxvgl0TuBz43VOBpQV8EbOeceyWdlZ8KvAzs4Zy7Z6IZ0guD7wa2Tz82BHSb4Ojux+/C+BvgmkarPpHtdkXmmgq7wMql6ruBPYCPUrxZdLc8BVyML+9LG636s4HzSB9TYRdMuVRdD1/SH8Ove0v3vAj8CvgR8AdduJRuU2EXQLlUXQm/1LIn8LbAcYriH/iThM5stOp/Dx1G+oMKu4+VS9XNgQPxFy5D3wtdVA5/sfJM4PxGq/584DySYyrsPlMuVRfBn5qzP/7CpWTHk8D3gO80WvVJv19e+o8Ku0+US9U18CW9L7BU4DgytpeAnwDfbrTq7dBhJD9U2DlXLlWnAUfhLyTOHziOTIzD36L57Uarntn9YCQ7VNg5VS5V3w58BdgNbZPbD24Cqo1W/ZLQQSS7VNg5Uy5V18EfFvxRVNT96GrgiEarfmPoIJI9KuycKJeqq+L3DNkLLX0Uwa+BIxut+l2hg0h2qLAzrlyqLgx8EX9wQVf2CpHceBU4G79U8s/QYSQ8FXaGlUvV3fB7Xr8pdBYJ6iUgAY7RfdzFpsLOoHKp+g7gJGCb0FkkU/4BVBqt+i9DB5EwVNgZUi5VpwJfBz6H1qlldJcC++mR9+JRYWdEuVTdCX9c2Mqhs0guPI+/WyjR4QrFocIOrFyqLgmcSHoQr8gE3QJ8qtGq3xI6iEw+FXZA5VJ1e+CHwCqhs0iuvYx/iOp4bena31TYAZRL1SXwV/0/FTqL9JUrgL0brfq/QgeRyaHC7rF0y9NzgNVCZ5G+9CTwuUarfn7oINJ9KuweKpeqhwLHocOPZfKdCRzUaNWfCx1EukeF3QPphcUz8QcJiPTK34CPNFr1W0MHke7Q5kGTrFyqrg/8GZW19N5awPXlUnX30EGkOzTDnkTlUvVTwCnAwqGzSOEdBxzVaNVfCx1E5p4KexKUS9UFgFOBT4fOItLhYmDPRqv+n9BBZO6osLssvWXvfOB9obOIjOBu4EONVv3u0EFk4rSG3UXlUnUV4FpU1pJd6wDNcqm6Q+ggMnEq7C5JLy7eCKwXOovIHCwJ/LZcqsahg8jEqLC7oFyqboefWb8xdBaRcZoCnFUuVQ8OHUTGT4U9j8ql6r74k68XD51FZIIMOLFcqh4TOoiMjy46zoNyqXogcHLoHCJd8H1gf932l20q7LmU/ih5YugcIl10HhA3WvWXQweRkamw50K5VK3gd9sT6TeXADurtLNJa9gTVC5VD0NlLf1rB+DccqmqDcoySIU9AeVS9YvA8aFziEyynfF3kKgfMkb/h4xTWtbfDJ1DpEf2BH5QLlUtdBB5nQp7HMql6idRWUvxfBpdWM8UXXScg/TcxQvRoQNSXMc2WvUjQ4cQFfaYyqVqCbgaeEPoLCKBHdZo1U8IHaLoVNijKJeqawB/BFYInUUkA17D3+53YeggRabCHkG5VF0WuB5YO3QWkQx5Dti80arfFjpIUemi4zDlUnUR/Jq1ylpkdosBF5ZL1RVDBykqFfb/+gHwrtAhRDJqVeDX5VJVx94FoMLuUC5V9we0R7DI2CLgx7pHu/dU2KlyqbopMD10DpGc2B34SugQRaOLjkC5VF0euBkdQCAyEa8B72u06leEDlIUhZ9hl0vV+YFzUVmLTNR8wE/SCY/0QOELGzgO2Dp0CJGcWgk4W+vZvVHowi6Xqh8CDgudQyTnysDhoUMUQWHXsNN7SWcAy4bOItIHZgJbNFr1G0MH6WdFnmGfgcpapFumAD8rl6pTQwfpZ4Us7HKp+nlgx9A5RPrM6sCpoUP0s8ItiZRL1TcDt6Md+EQmywcarfrvQofoR4Uq7PRK9pXAVqGziPSxfwFva7Tqz4QO0m+KtiSyPyprkcm2Cv52Wemywsywy6XqqsBdaClEpBccsGWjVb8udJB+UqQZ9gmorEV6xYDTy6XqQqGD9JNCFHa5VH0P8JHQOUQKZh20QVRX9f2SSLlUnQLcBrw1dBaRApoJrNdo1e8KHaQfFGGGfSAqa5FQpgBJ6BD9oq9n2OVSdQXgHmCJ0FlECm7HRqt+SegQedfvM+xvobIWyYIkXZ6UedC3hV0uVTdBx32JZMU04DOhQ+Rd3xY2cAz+1iIRyYZquVRdLHSIPOvLwi6XqpsD7wudQ0RmswLaf36e9GVhA0eHDiAiIzqsXKouFzpEXvVdYacPyWwdOoeIjOgNQCV0iLzqu8IGvhY6gIiMab9yqbpk6BB51FeFXS5Vy8BmoXOIyJiWxO+cKRPUV4WNZtcieXFIuVRdJHSIvOmbwi6XqlsBm4TOISLjshzw6dAh8qZvChs4KHQAEZmQw8ql6gKhQ+RJXxR2uVR9E/Ch0DlEZEJWA/YKHSJP+qKwgQOA+UOHEJEJ0y1+E5D73frKpeob8Id+Tg0cRUTmzqaNVv3G0CHyoB9m2DEqa5E8+1zoAHmR6xl2uVQ14C/AuqGziMhcewFYudGqPx06SNblfYa9DSprkbxbBG2FPC55L+xPhA4gIl3x2dAB8iC3SyLpU1KPAouHziIiXbFZo1W/IXSILMvzDPtDqKxF+olm2XOQ58LWDfci/WWXcqm6UOgQWZbLwi6XqssC5dA5RKSrlgC2Cx0iy3JZ2MDugE5gFuk/u4UOkGV5LWwth4j0pw9qQ6jR5a6wy6XqqsC7QucQkUkxFdg2dIisyl1hAzuFDiAik0rLIqPIY2HvGDqAiEyqnculqq5RjSBXhZ3e8vOe0DlEZFItDWwdOkQW5aqwga2AN4QOISKT7n2hA2RR3gpbyyEixfDe0AGySIUtIlm0YblUXSp0iKzJTWGXS9W1gLeEziEiPTEfWsf+H7kpbPQjkkjR6L/5YfJU2JuGDiAiPaU7woZRYYtIVq1bLlVXCh0iS3JR2OVSdRlg7dA5RKTntgkdIEtyUdho7xCRoto4dIAsUWGLSJZtFDpAluSlsLV+LVJMG5RLVQsdIisyX9jlUnU+YJPQOUQkiCWBN4cOkRWZL2z8xUYdtitSXBuGDpAVeSjsdUMHEJGgtI6dykNhTwsdQESC0gw7pcIWkaxTYadU2CKSdSuUS1VdxyIfhb1O6AAiEtwaoQNkQaYLu1yqroi/rUdEim310AGyINOFjZZDRMTTDJvsF7YOLBARUGED2S/sVUIHEJFMUGGT/cJeOXQAEcmE1UMHyAIVtojkgWbYZL+wddqEiAAsXi5VFw0dIrSsF/byoQOISGZMDR0gtKwX9rKhA4hIZkwNHSC0zBZ2+ijqQqFziEhmLBU6QGiZLWw0uxaR2U0NHSC0LBd24S8wiMhsNMMOHWAMWg4RkU5TQwcITYUtInmhGXboAGNQYYtIp8VCBwhNhS0ieTF/6AChqbBFJC+y3Fc9keX/AVTYItKp8DPsKaEDjGHB0AEkEx4HjgReCx1EgvtL6AChZbmwXegAEpwD4karfmnoICJZkOUlkRdCB5DgjlNZi7wuyzNsFXaxXQN8ZfjgtNr0+YHPAG/veSLJmpPatcpfQ4foJRW2ZNG/gT0arfqrw/+gXau8Oq02/QzgEKAKvKHH2SQ7zgMKVdhZXhJ5PnQACcIBezVa9Yc6B6M42T2KkzJAu1Z5pV2rHA9MA84PkFGy4X/+Qu93WS5szbCL6RuNVv2yzoEoTtYDfgxcGsXJ+VGcrALQrlX+1a5VPgJsD/yt50klNBV2hmiGXTxX45c5ZoniZDH8j74Lp0MfBu6K4uTwKE6mALRrlQZ+TfurwIu9iyuBqbAzRDPsYnmMkdetfwCsM2xsMeBbwK1RnGwJ0K5VXmrXKkcDbwMumuywkgnPhQ7Qa1ku7GdCB5CeeQ2/bv1w52AUJ58F9hzjdW8Dro7iZDCKkxUA2rXKfe1a5f3AzsADk5RXsuGp0AF6LbOF3WjV/0sB/wYtqG80WvXLOweiOFkfOGmcr98LuDuKkwOiOJkfoF2r/AZ4K3As8HI3w0pmPBk6QK9ltrBTD835UyTnrgJqnQNRnCzO7OvW47Ek8B3gpihOIoB2rfJ8u1Y5ElgP+EM3wkpmPN+uVQr3F7EKW0J6lJHXrU8D1p7Lr7kh8McoTk6L4mRpgHatcne7VtkW2AN4eMxXS14UbnYN2S9s/cfVv4bWrR/pHIzi5HPAx+bxaxv+ach7ojj5dBQnBtCuVX6Ov3f7RAp4h0GfKdz6NWS/sDXD7l/HNFr133cORHGyAb5Mu2UZ4IfA9enXpl2rPNOuVSrARsD1XXwv6S3NsDNIhd2frgTqnQNzuW49XpsCf47i5OQoTpYAaNcqtwNbAPviH4WXfNEMO4NU2P3nUWDPRqs+fH/rHwJvmcT3nR84EH83yccB2rWKa9cqZ+Lv8/4+2nM7TzTDzqAHQweQrnoNX9bD162/AOzeowwrAj+J4uSKKE7WBWjXKk+1a5UvAO8CWj3KIfPmH6EDhJD1wm6HDiBddXSjVb+icyCKkw2B6QGybAPcFsXJN6M4eQNAu1a5CdgE2A94OkAmGb9C7h2T6cJutOr/xh8RJfn3B+BrnQPpevJ5hDu/cwHgi/i9SXYFaNcqr7Vrle/hl0nOQicfZdW9oQOEkOnCTt0ZOoDMs0eAj4+ybr1WgDzDrQpcEMXJxVGcrAnQrlUea9cq+wBbAXeEDCcjUmFnVOEP3sy5oXXrRzsHozjZD/homEij2gG4I4qTWhQnCwO0a5Vr8Q/jHIq2SsiKZ9u1SiHv7MlDYWuGnW/1Rqt+ZedAFCcbAUmgPHOyMH6L1zuiONkBoF2rzGzXKgn+oZvzQoYToKCza1Bhy+T6PXBM50AG1q3Ha03g4ihOfhnFyWoA7VrlwXatsjuwHXBP0HTFVsgLjqDClsnzMCOvW5+BL8O82AV/UfKIKE4WAGjXKpcD7wC+jPZtD0Ez7KxK79l9InQOmZBX8evWj3UORnFyALBbmEjzZFH8Nq23RXGyDUC7Vnm5Xat8Hb+F64UhwxVQoQ7e7ZT5wk41QweQCak3WvWrOgeiOCkB3w4Tp2vWBa6I4uScKE5WBGjXKve3a5UPAh8E7g8ZrkBuDh0glLwUtjbpyY/Lga93DkRxsiT5WLcerz3xj7gf3HFgwoX42fYx6MCEyfQiMCN0iFBU2NJNDzH6uvWbA+SZTEvgdxb8cxQnmwK0a5UX2rXKV/Dr25eP8VqZe7e2a5WZoUOEkpfC/hPwSugQMqahdevZ7o+N4uRA/Enn/WoD/PatZ0RxsixAu1a5p12rbIffH0X74XTXTaEDhJSLwm606i8At4TOIWOqNlr1qzsHojjZmPyvW4+H4bdpvTuKk892HJhwHv7e7ROAws4Ku0yFnRNaFsmuy4BvdA50rFsvGCRRGEsDP8AfUbYRQLtWea5dqxyGf1ry2pDh+sSfQgcIKU+FfV3oADKih/BHfQ3fJOlHwBoB8mRBhD8M+JQoTqYCtGuVO9q1ypbA3sBjY71YRvUfCv7AUp4KWzPs7HkVf4ju8HXrg4Fdw0TKjPmA/YF2FCfx0GC7VjkbvxPgqejAhIlqtWuVQu+eaM7l5/svl6q3AuuHziGzHNVo1YcvhbwT/9NQkZZCxuNqYP/m4MCszcym1aaX8MW9SbBU+fL1dq3y5dAhQsrTDBv0RFmWXIp/+m+W9Mf/oq1bj9dWwK1RnBwfxcliAO1apYU/b/LzFPTIqwn6Q+gAoamwZW48CMQjrFufCaze+zi5MQU4DL83yW4w68CEH+CXSX6EDkwYzfNoWTR3SyKG31RohdBZCuxVYOtGqz7bReAoTg4hzFFfeXYZcEBzcGDW3hjTatPfDXwPWC9YqmxqtGuV7UOHCC1XM+x0RndR6BwF9+URynoT4FuB8uTZdsCMKE6OjuJkEYB2rXIDsBFQAZ4NGS5jRn1y1MwONrM7zOwvZnZIOvZNM7vdzM7u+LzYzA7uQdZJk6vCTv0udIACuwT4ZudAFCdLAefiz0eUiVsIv03rX6I4eT9Au1Z5tV2rnIhfJvl5wGxZcvFIg2b2duAz+Au36wPvN7P1gXc759YD5jezd5jZIsA++Iu8uZXHwr4MeCl0iAL6F/AJrVtPmjWAC6M4+U0UJ28CaNcqD7drlT2A9wLtoOnC+nu7VrlrlD9bF7jROfe8c24m/m6cnYEFzcyARfDbWhwOnOycy/UWF7kr7Ear/l/gitA5CmYm8LFGqz7bCfZRnAwAHwoTqW99ELgzipMjozhZEKBdq1yBnz3+H/7iW9GMtQx6B7ClmS1jZosCOwLLAhfgt7P4O/6Bm3c6534znjczM2dmJ3T8/jAzq81NcDObamb7zc1rR5K7wk79LHSAgvlyo1Wf7Qp9FCcRcFygPP1uUfwWtbdHcfJemHVgwnH4LVx/HTBbCKMWtnPuLvwy3eX4W01vA2Y6577lnNvAOXcocDTwVTP7tJmdZ2Zzupf7JWBXM1u2C9mnAiMWtpnNP9EvltfC/iU6wbpXLmLYBUWtW/fMOsDvozj5eRQnKwO0a5UH2rXKLsBOwH1B0/XGk8zh/mvn3BnOuY2cc1umnz/rrhsz2zD95T3AJ5xzHwXebmZvGeNLzgROw1/4nY2ZLWdmF5jZTenHZul4zcwO6/i8O8xsdfykZk0zu9XMjjezrc3sSjP7KTDDzBY2szPNbIaZ3WJm24z1veaysNNlkQtC5yiAfwJ7j7BufRbwpgB5imp3/CPulShOpgC0a5WLgbcBX6O/r+n8ol2rjLnubGbLp/9cDb8lQudP4EcDX8VPLoZmtK/hf4oZy3eBj5vZksPGTwKmO+feid82+PQ5fJ0jgHvT2f7h6dgmwFHOubfity/AOfcOYA/gLDNbeLQvlsvCTp0VOkCfG1q3nu08zShODgU+ECZSoS0OJEAripPNANq1yovtWqUKvB2/HNCPzhnH51xgZnfiH6zb3zn3FICZ7Qzc5Jx7yDn3NPBHM5sBOOfcbWN9QefcM8DZwEHD/mhb4BQzuxX4LbCEmS0+ge8H4E/Oub+nv94cGEzfsw08AKw92gunTPCNsuQq/Denmd7kOLLRqt/QORDFybsY9ji69Nx6wLVRnJwFfLE5OPDvdq3yN2CHabXpH8afgrNKyIBd9A/GsUunc26LUcZ/Tcd6v3PuMPyTpuN1Iv78yDM7xuYDNnXOvdD5iWY2k9knwKPOkoH/dr50AnnyO8NOf0z/Segcfep3DDt4IIqTpdG6dVYY/p7iu6M4+XwUJ/MBtGuVC/C3uR1Pf5zQ9LOQu/M5557E743zqY7hy4ADhn5jZhukv7wf/8ATZrYRr28t/Cz+p6PRXAN8PH3d2sBqwN2jfXJuCzt19pw/RSbof9at0xNUzsL/yyTZsRT+MfZmerrP0IEJX8QfXXb1GK/Ng/Esh0y2E/C3CQ45CNg4fYryTvzGXeCvqS2dLpV8gXTfbufcE8D16UXI40f4+qfiH+6ZgZ8Q7eOcG/WaRK72EhlJuVS9DtgsdI4+8QqwVaNV/2PnYBQnh6NHz7PuNfydDUc2BweeGhqcVpu+F/6npbztvzOjXatoP5Vh8j7DBn81V7rjyBHKelOGHf8lmTQffrZ3dxQn+3ScK/kT/O2Bp+A37sqLLMyuM6cfCvt8/DFVMm8uxP/4N0sUJ8vgf0zL88XpolkOf5HsmihO3gHQrlX+065VDgTeCTRDhhunmej61IhyvyQCUC5Vv4y/31LmzgPAho1WfdaP0ukM7UL8AxqSTzOBk4Fac3DgWYBptemGv4h2HLBMwGxjObddq3wsdIgs6ocZNviTql+Y42fJSF7B32/91LDxw1FZ590UYAD/0M3uAO1axbVrldPxyySnk80DE04KHSCr+mKGDVAuVb/H61dsZfwObbTqSedA+mDGVWgppN/8Hn+u5KyTx6fVpr8Lf6fChqO+qrduatcqOuNyFP0ywwb/FJhOoZ6Y345Q1svg92BWWfefbfEHJny948CEG/Fr2wfhd7ULTbPrMfRNYTda9b8C49o+UQC/br1P50C6bn02/fOknPyvBYEj8Vu4fhBmHZjwHWAaYe/OeBj/oIqMom8KO/X10AFy4hVg9xHWrb+I309Y+t/qwG+iOLkwipM1ANq1yiPtWmUvYBvgzgCZvjenjZ6Krq8Ku9Gqt/Bbr8rYvtRo1We7vSuKk82BYwLlkXDejz+e7CtRnCwE0K5VrsI/KfklZt/3YjK9hL95QMbQNxcdh5RL1XXxp1D01V9GXfTrRqu+S+dAFCfLArcCbwySSLLir/iLkrMOvJ1Wm74qfhOkXSf5vU9v1yqfmeT3yL2+K2yAcql6FvCJ0Dky6H78/dZPDw2k69YXA9sHyiTZ8wug0hwceHBoYFpt+vbAd4C1JuH9Xgbe0q5V/jEJX7uv9OsstIr/l0BeN7Ru/fSw8SNQWcvsPoK/d/vQjgMTLsXvu10DXuzy+52msh6fvpxhA5RL1e8yyllqBXVIo1Wf7ZapKE62AK7k9ZM4RIa7A9ivOThw7dDAtNr0N+Nn2924QP0C8OZ2rfJIF75W3+vnwl4RuJc5HwVUBL9qtOqzrUFGcbIc/lRprVvLeAwChzUHBx4bGphWm74Lfn17XrbdPT7dDlbGoV+XRGi06o/g/2Uqur8D+3YOpOvWg6isZfxi/E6A+3ccmPAr/IEJ32TuDkx4Nn2tjFPfFnbqG/gN+YvqZeCjI6xb/x9Q7n0cybmp+G1a/xTFySYA7Vrl+XatcgSwPn55bSJObNcqT8z502RI3y6JDCmXqrtS3BPWD2606id3DkRxsiVwBVq3lnnzGn7zqP9rDg48OTQ4rTZ9T/w2vSvO4fVPAWu0a5UsPA6fG31f2ADlUvViYIfQOXrsgkarvlvnQBQny+PXrVcOE0n60OP4B2zObA4OOIBptelLAF/Dn3042sTg8Hat8u1R/kxG0e9LIkMOpPu3ImXZfcx+cCjpuuNPUFlLdy0LnAFcF8XJ+gDtWuWZdq1yCFACbhjhNW20ydNcKURhN1r1eynOxY2hdevhP2oeCbwvQB4phncDrShOToziZAmAdq1yG7A5fvLweMfnHqQ9Q+ZOIZZEAMql6sL4e0rXDJ1lkh3YaNVP6RyI4mRr/F7IWreWXngYOLQ5OPCzoYFptelLA8cCy7Rrld1GfaWMqTCFDVAuVcvApaFzTKLzG636RzoH0nXrW4GVgiSSIrsCvzdJe2hgWm36fO1aRfvWz6VCFTZAuVT9AfDZ0Dkmwb3ARo1W/ZmhgXTd+lK0FCLhvIK/a+To5uDA86HD5F0h1rCHGcDvStZPXsKvWz8zbPwoVNYS1gL4gzIWDJyjLxSusBut+n/xT229GjpLFx3aaNVv7hyI4mQb/EY9IqEd3BwceDp0iH5QuMIGSDfv/0boHF1yXqNV/27nQBQnKwA/paD//0qmXNQcHNCxX11S5P+gvwbcFDrEPPobMNum7+m69TnM+Ukzkcn2X2D/0CH6SWELu9GqzwT2AvJ6IWS0deuvAO8NkEdkuK82BwceCB2inxS2sAEarfo9wCGhc8ylSqNVv6VzIIqT9wBfDZRHpFMLPc3YdYW7rW8k5VL1NIYtLWTcuY1W/WOdA1GcrIi/33qFIIlEXvcMUGoODvwtdJB+U+gZdocDgOYcPysbxlq3VllLFuyrsp4cKmyg0aq/DHwYeDR0ljl4EfhIo1V/dtj4V4H3BMgjMtxJzcGBom5nPOlU2KlGq/4g/vDRLG9KU2m06rd2DkRx8l78hUaR0JrA4aFD9DOtYQ9TLlUPwB8wmjU/b7Tqe3QOaN1aMuRJYMPm4IBOP59EmmEPk+509+PQOYa5h2H7n0RxMj/+4RiVtYTmgFhlPflU2CP7HH470ix4EX+/9fB16yqwTYA8IsMd1xwcuDh0iCJQYY8gvQi5K3DznD63Bw5utOq3dQ5EcbItfmMnkdCuQtdQekZr2GMol6rLA9cDawWK8NNGq/7xzoEoTlbCr1svHySRyOsewa9bPxI6SFFohj2GRqv+GFAmzO1+9+CXZmbpWLdWWUtorwJ7qKx7S4U9B41W/T78ievD15An0wv4+62fGzZeA7buYQ6R0RzVHBy4KnSIolFhj0O6Z8fO+ANue+HgRqt+e+dAFCfb4Q/SFQktaQ4OFOVQ60zRGvYElEvVnYALgIUm8W3OabTqe3UORHGyMn7derlJfF+R8TijOTjw6dAhikoz7AlotOoXAR/AL1lMhjYjr1v/DJW1hHce/Xkeam6osCeo0apfDuyE35y9m17A3289/Ot+Ddiyy+8lMlGXAHs1Bwd04nlAWhKZS+VSdXPgYmDxLn3JTzda9TM6B9J160sB69J7iMyNa4Fyc3Bgsn6ylHFSYc+Dcqka4Qt16jx+qcFGq/6JzoEoTt4I3IKWQiSsFvCe5uDA8JONJAAticyD9DDf9wKPz8OXaQNf6BzQurVkxF3A9irr7FBhz6NGq34z8C78gy4T9Tz+fuvh69ZHA1vMazaReXA/8L7m4MC8TEaky1TYXdBo1e8FNgWunuBLD2y06nd0DkRxsj1wRLeyicyFh4Ftm4MDD4YOIrNTYXdJo1V/EtgOOHucLzm70ar/qHMgXbceRBcZJZyHge2agwP3hg4i/0uF3UWNVv3lRqu+N373srGu5t4F7Nc5EMXJFODnwLKTl1BkTDOAqDk4cMccP1OCUGFPgkarfgywJ/DSCH882rr1McDmk51NZBSXAZs3Bwf+GTqIjE6FPUkarfrPga2A4f8B7N9o1f/SORDFyQ7AF3uVTWSYHwI76W6Q7NN92JOsXKouC5yDX98+q9Gq79P551GcrILfJ2SZnoeTonPAkc3BgeNCB5Hx0Qx7kjVa9cfx27MexOjr1ipr6bUX8ftZq6xzRDPsgKI4+SZaCpHeexz4UHNw4IbQQWRiVNiBRHGyE3AhuoVPeuuvwI7NwYG/hQ4iE6fCDiCKk1Xx+4RoKUR66Tpg5+bgwBOhg8jc0Rp2j2ndWgI5Hf/0oso6x6aEDlBAHwXeHTqEFMbTwGebgwO/CB1E5p1m2D3WHBz4KbAv3T8AQWS464D1Vdb9Q4UdQHNw4ExgI+Dm0FmkL70K1ICtm4MD/wicRbpIFx0DiuJkQeBYoILuFpHuuBfYuzk4cH3oINJ9KuwMiOKkjH88eNXQWSS3HPAd4P+agwPPhw4jk0OFnRFRnLwB+DIwACwYOI7ky33Avs3BgYnuxy45o8LOmChO1sbPlLYLnUUyzwGnAl9qDg7oInYBqLAzKoqTDwPT0TKJjKwJHKq16mJRYWdYFCeL4pdJDkXLJOLdh1+nPi90EOk9FXYOpMskJwPl0FkkmCfxhzOf2hwceDl0GAlDhZ0jUZzsil8mWS10FumZl/B/WX+jOTjwdOAsEpgKO2fSZZIjgIOBJQLHkcnjgJ8CRzUHBx4IHUayQYWdU1GcLAl8HjgEWDFsGumyK4HDm4MDrdBBJFtU2DkXxclCwCeAw4G3BI4j8+Y2/Iz6otBBJJtU2H0iipP5gF2BLwEbB44j4zcT+BVwSnNw4JrQYSTbVNh9KIqT9+CLWw/fZNejwGnA95uDAw+FDiP5oMLuY1GcbIgv7t2A+QPHEe8G4LvA+bo9TyZKhV0AUZy8Gb8H98eANQPHKaIXgJ/hlz1uCR1G8kuFXTBRnGwM7IE/+WaVwHH63d+B7wFnNAcHngwdRvJPhV1QUZwYsDl+1r0bsHzYRH3jTuC36UezOTjwWuA80kdU2EIUJ/MD78GX9y7AUmET5cpM4FrSkm4ODtwXOI/0MRW2zCY9BacM7I6/y2S5sIky6T/AJfiSvkSPjEuvqLBlVOmyyduArYCt038WtcD/DlyIL+lrmoMDrwTOIwWkwpZxSwv8rcCWQJR+rEP/nUf5LNAC/jT00Rwc+GfYSCIqbJlH6Z4m7wQ2wRf4O/CHLkwJmWsCHgHuAGYAtwM3AXfpYqFkkQpbui69iLky8CZg9RH+uRqwUA+iOOAp4LGOj0eBe/AFPaM5OPB4D3KIdIUKW3ouXVpZkdcLfFVgEWCBjo8p4/j1TODfvF7Ejw37+HdzcGBmj74tkUmnwhYRyYn5QgcQEZHxUWGLiOSECltEJCdU2CIiOaHCFhHJCRW2FIqZrWpmV5rZXWb2FzM7OB0/18xuTT/uN7Nb0/HNzOx2M7vJzNZKx6aaWcPM+u0JT8m4vDyNJtItM4FDnXM3m9niQMvMLnfO7T70CWZ2An6DJ4BDgQ/j7xf/Qvr7rwDfcLonVnpMhS2F4px7GHg4/fWzZnYX8Eb8Ptaks+aP4rebBXgF/1DPosArZrYm8Ebn3NW9zi6iwpbCMrPVgQ2BZsfwFsCjzrm/pr8/Fn9Y7gtADHwbP8MW6TkVthSSmS0GXAAc4px7puOP9sCfvwiAc+5W4F3pa7YEHvK/tHPxs+9DnXOP9iq3FJseTZfCMbMFgN8BDedc0jE+BXgQKDnn/jXsNQY08Ac7nAIcjV/X3sI5d1SPokvB6S4RKZS0eM8A7uos69S2QHt4Waf2Bi5yzj2FX89+Lf1YdDLzinTSkogUzWb4tegZQ7fuAUc65y7Gn2n5s+EvMLNF8YW9XTqU4JdTXsYvoYj0hJZERERyQksiIiI5ocIWEckJFbaISE6osEVEckKFLTIHZubS/UWGfn+YmdUm4X2OHPb7G7r9HpJvKmyROXsJ2NXMlp3k95mtsJ1z757k95OcUWGLzNlM/H4ileF/YGbLmdkF6farN5nZZh3jl5vZzWb2AzN7YKjwzezXZtZKt3f9bDp2HLBIur3rOenYc+k/zzWzHTve88dm9mEzW9jMzjSzGWZ2i5ltM+n/S0hQug9bZA7S4lwZuB1YH/gMsJhzrmZmPwVOdc5dZ2ar4R93X9fMTgEedM4da2bbA5cAyznnHjezpZ1zT5rZIsBNwFbOuSfM7Dnn3GKd7+ucW8zMdgF2ds7tbWYLAvcCawP7AW93zn3SzKYBlwFrO+de7Nn/ONJTetJRZBycc8+Y2dnAQfid+4ZsC7y14yyDJdJ9tjcHdklfe6mZPdXxmoPSEgZYFXgL8MQYb38JcLKZLQRsD1zjnHvBzDYHvpO+R9vMHsAX+e3z8K1KhqmwRcbvROBm4MyOsfmATZ1znSU+tGfJ/zCzrfElv6lz7nkzuwpYeKw3dc69mH5eGb/51NDj8zrxpmC0hi0yTs65J4HzgE91DF8GHDD0GzPbIP3ldfiDEDCz7YCl0vElgafSsp5GunVr6pV0J8GR/Bz4JH6/7kY6dg3w8fQ91gZWA+6em+9N8kGFLTIxJwCdd4scBGycnvt4J/D5dLwObGdmNwM74E+5eRa4FJhiZrfjt2i9seNrnQbcPnTRcZjLgC2B3zvnXk7HTgXmN7MZwLnAPs65l7rxTUo26aKjyCRI15tfdc7NNLNNge855zYIHEtyTmvYIpNjNeA8M5sPvw3rZwLnkT6gGbaISE5oDVtEJCdU2CIiOaHCFhHJCRW2iEhOqLBFRHJChS0ikhMqbBGRnPh/X5LgVUNmhMkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment = pd.DataFrame(dataset['sentiment_label'].value_counts())\n",
    "labels = ['Positivo', 'Negativo', 'Neutro']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = sns.color_palette('viridis')\n",
    "ax.pie(sentiment['sentiment_label'],labels= labels,autopct='%1.0f%%', pctdistance=1.1, labeldistance=1.2, explode = [0.02, 0.02, 0.02], colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criando uma BaseLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos definir uma baseline para o modelo de classificação de sentimos supervisionado. A baseline é um modelo simples de previsão que atua como referência para futuros modelos de Machine Learning, algumas informações aqui descritas serão explicadas e demostradas ao longo do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Bag of Words: criando representações da linguagem humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40977, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vetorizando as 50 palavras com mais ocorrência da coluna \"review_comment_message\"\n",
    "vetorizar = CountVectorizer(max_features=50)\n",
    "bag_of_words = vetorizar.fit_transform(dataset['review_comment_message'])\n",
    "bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ainda' 'antes' 'as' 'até' 'bem' 'bom' 'chegou' 'com' 'como' 'compra'\n",
      " 'comprei' 'da' 'de' 'dentro' 'do' 'em' 'entrega' 'entregue' 'estou' 'eu'\n",
      " 'excelente' 'foi' 'gostei' 'loja' 'mais' 'mas' 'me' 'meu' 'minha' 'muito'\n",
      " 'na' 'no' 'não' 'os' 'para' 'por' 'prazo' 'produto' 'qualidade' 'que'\n",
      " 'recebi' 'recomendo' 'rápida' 'super' 'só' 'tudo' 'um' 'uma' 'veio'\n",
      " 'ótimo']\n"
     ]
    }
   ],
   "source": [
    "# Visualização das 50 palavras com mais ocorrência\n",
    "print(vetorizar.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Modelo: LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     8745\n",
       "2     2145\n",
       "3     3557\n",
       "4     5976\n",
       "5    20554\n",
       "Name: review_score, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar a proporção do review score\n",
    "dataset.review_score.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:[0.7567944  0.75861866 0.75916878 0.7594724  0.76023611 0.76070996\n",
      " 0.76244324 0.76274105 0.77094021 0.77662594]\n",
      "Média: 0.7627750743117272\n",
      "Desvio Padrão: 0.005884688391941579\n"
     ]
    }
   ],
   "source": [
    "regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "scores = cross_val_score(regressao_logistica, bag_of_words, dataset['sentiment_label'], cv=10, scoring=scorer)\n",
    "print(f'f1_score:{np.sort(scores)}')\n",
    "print(f'Média: {scores.mean()}')\n",
    "print(f'Desvio Padrão: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de confusão é a forma mais simples de analisar o desempenho de um algoritmo de classificação, sendo base para os cáculo das métricas dela derivadas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = bag_of_words\n",
    "y = dataset['sentiment_label'].map({-1: 'negativo', 0: 'neutro', 1: 'positivo'})\n",
    "\n",
    "# Cria 3 partições com os dados de disponíveis\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X, y)\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Criação do modelo\n",
    "    regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, regressao_logistica.predict(X_test)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=['Negativo', 'Neutro', 'Positivo'], columns=['Negativo', 'Neutro', 'Positivo'])\n",
    "    plt.figure(i)\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\", fmt='g')\n",
    "    i += i\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Precisão e Revocação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A metrica precisão do classificador (precision_score) é a acurácia das previsões positivas. O melhor valor é 1 e o pior valor é 0.\n",
    "\n",
    "$$ precisão = \\frac {TP}{TP + FP} $$\n",
    "\n",
    "- TP: número de verdadeiros positivos\n",
    "- FP: número de falsos positivos\n",
    "\n",
    "A precisão é utilizada em conjunto com outra métrica chamada revocação (recall_score), também conhecida como sensibilidade ou taxa de verdadeiros positivos (TPR, do inglês): esta é a taxa de instâncias positivas que são corretamente detectadas pelo classificador.\n",
    "\n",
    "$$ revocacão = \\frac {TP}{TP + FN} $$\n",
    "\n",
    "- TP: número de verdadeiros positivos\n",
    "- FN: número de falsos negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Pontuação F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma simples de comparar dois classificadores é através da métrica chamada pontuação (F1). A pontuação F1 é a média harmônica da precisão e revocação. Enquanto a média regular trata igualmente todos os valores, a média harmônica dá muito mais peso aos valores mais baixos. Como resultado, o classificador só obterá uma pontuação F1 alta se a revocação e a precisão forem altas.\n",
    "\n",
    "$$F_1 = \\frac {2}{\\frac {1}{precisão} + \\frac {1}{revocacão}} = \\frac {precisão * revocacão} {precisão + revocacão} = \\frac {TP} {TP + \\frac {FN + FP} {2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4. Analise precisão, revocação e pontuação (f1) para cada classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7641533151796949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.73      0.72      0.72      3630\n",
      "      neutro       0.31      0.02      0.04      1185\n",
      "    positivo       0.83      0.94      0.88      8844\n",
      "\n",
      "    accuracy                           0.80     13659\n",
      "   macro avg       0.62      0.56      0.55     13659\n",
      "weighted avg       0.76      0.80      0.76     13659\n",
      "\n",
      "f1_score: 0.7647160778158226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.73      0.71      0.72      3630\n",
      "      neutro       0.30      0.02      0.03      1186\n",
      "    positivo       0.83      0.94      0.88      8843\n",
      "\n",
      "    accuracy                           0.80     13659\n",
      "   macro avg       0.62      0.56      0.55     13659\n",
      "weighted avg       0.76      0.80      0.76     13659\n",
      "\n",
      "f1_score: 0.7578329397156042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.72      0.70      0.71      3630\n",
      "      neutro       0.25      0.01      0.03      1186\n",
      "    positivo       0.82      0.94      0.88      8843\n",
      "\n",
      "    accuracy                           0.79     13659\n",
      "   macro avg       0.60      0.55      0.54     13659\n",
      "weighted avg       0.75      0.79      0.76     13659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definindo X e Y\n",
    "X = bag_of_words\n",
    "y = dataset['sentiment_label'].map({-1: 'negativo', 0: 'neutro', 1: 'positivo'})\n",
    "\n",
    "# Cria 3 partições com os dados de disponíveis\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Criação do modelo\n",
    "    regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, regressao_logistica.predict(X_test)\n",
    "    score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'f1_score: {score}')\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estrutura do Pipeline de trasformação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será utilizado a classe Pipeline do Scikit Learn para executar uma preparação dos textos de cada comentário de forma automática, deixando pronto para treinamento e previsão do rótulo de sentimento. As etapas do pipeline são:\n",
    "\n",
    "- Remoção das expressões regulares: sabendo que os dados são fruto de comentários da internet, será necessário lidar com algumas expressões regulares. Iremos realizar o pré-processamento dos dados, substituído as expressões regulares por termos que as caracterizem de forma simples;\n",
    "\n",
    "- Remoção de StopWords: As stopwords são palavras que não apresentam relevância em determinado contexto e podem ser removidas sem perda semântica da frase;\n",
    "\n",
    "- Normalização dos comentários: pega os dados Unicode e tenta representá-los em caracteres ASCII (ou seja, os caracteres universalmente exibíveis entre 0x00 e 0x7F), onde os compromissos assumidos ao mapear entre dois conjuntos de caracteres são escolhidos para estar perto do que um humano com um teclado americano escolheria;\n",
    "\n",
    "- Stemming: Stemming é a técnica que transforma as flexões de uma palavra em um núcleo comum (tronco).  Essa técnica normaliza as palavras de forma a evitar suas flexões e derivações. Existem diversos algoritmos para realizar a “stemmização\", seja em Português, sejam em outros idiomas;\n",
    "\n",
    "- Extração de features: A extração de features de texto envolve resumir automaticamente o texto e encontrar palavras importantes. A extração de palavras poderá ser feita de duas formas:\n",
    "    - CountVectorizer: converte uma coleção de documentos de texto em uma matriz de contagens de token, ou seja, produz uma representação esparsa das contagens de frequência das palavras ao longo de todo o dataset;\n",
    "    - TF-IDF (Term Frequency-Inverse Document Frequency): é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico.  O TF-IDF irá contar a frequência das palavras e atribui pesos as mesmas, ponderando-as em todo o dataset. Se uma palavra aparece muitas vezes, ela perde o poder de diferenciação, logo, possuirá um peso menor.\n",
    "\n",
    "\n",
    "Todas as etapas do Pipeline foram modularizadas no diretório utils para tornar o programa mais \"limpo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo todas as trafomações regex para serem aplicadas ao pipeline\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=300) \n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "    ('text_features', ExtracaoFeatures(vectorizer))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "# Dfinido X e y \n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extração de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O CountVectorizer converte uma coleção de documentos de texto em uma matriz de contagens de token , ou seja, essa implementação produz uma representação esparsa das contagens de frequência das palavras ao longo de todo o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report_ngrams(vectorizer, ngram, nsplits, maxfeatures=None, mindf=1, maxdf=1.0):\n",
    "    regex_transformers = {\n",
    "        'datas': re_dates,\n",
    "        'valores_dinheiro': re_money,\n",
    "        'numeros': re_numbers,\n",
    "        'negacoes': re_negation,\n",
    "        'caracteres_especiais': re_special_chars,\n",
    "        'espacos_branco': re_whitespaces\n",
    "    }\n",
    "\n",
    "    vectorizer = vectorizer(max_features=300, ngram_range=ngram)\n",
    "\n",
    "    # Criando o Pipeline\n",
    "    text_pipeline = Pipeline([\n",
    "        ('regex', RemoverRegex(regex_transformers)),\n",
    "        ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "        ('normalization', ProcessoNormalizacao()),\n",
    "        ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "        ('text_features', ExtracaoFeatures(vectorizer))\n",
    "    ])\n",
    "\n",
    "    # Dfinido X e y \n",
    "    comentarios = dataset['review_comment_message'].dropna().index\n",
    "    score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "    X = list(dataset['review_comment_message'][comentarios].values)\n",
    "    y = score.values\n",
    "\n",
    "    # Aplicando o pipeline\n",
    "    X_processed = text_pipeline.fit_transform(X)\n",
    "\n",
    "    # Cria 3 partições com os dados de disponíveis\n",
    "    skf = StratifiedKFold(n_splits=nsplits)\n",
    "    skf.get_n_splits(X_processed, y)\n",
    "\n",
    "\n",
    "    for train_index, test_index in skf.split(X_processed, y):\n",
    "        X_train, X_test = X_processed[train_index], X_processed[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #Criação do modelo\n",
    "        regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42, max_iter=200)\n",
    "\n",
    "        regressao_logistica.fit(X_train, y_train)\n",
    "        y_true, y_pred = y_test, regressao_logistica.predict(X_test)\n",
    "        score = f1_score(y_true, y_pred, average='weighted')\n",
    "        print(f'Score para n-grams {ngram}')\n",
    "        print(f'f1_score: {score}')\n",
    "        print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1. N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8103191701205052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.83      0.80      2178\n",
      "      neutro       0.30      0.05      0.09       712\n",
      "    positivo       0.88      0.95      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.65      0.61      0.60      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8113515397535156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.83      0.80      2178\n",
      "      neutro       0.28      0.05      0.09       712\n",
      "    positivo       0.88      0.95      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.64      0.61      0.60      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.807308490271284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.83      0.79      2178\n",
      "      neutro       0.29      0.05      0.09       711\n",
      "    positivo       0.88      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8195\n",
      "   macro avg       0.64      0.61      0.60      8195\n",
      "weighted avg       0.80      0.84      0.81      8195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8053901199363199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.81      0.79      2178\n",
      "      neutro       0.30      0.05      0.09       711\n",
      "    positivo       0.87      0.95      0.91      5306\n",
      "\n",
      "    accuracy                           0.83      8195\n",
      "   macro avg       0.65      0.60      0.59      8195\n",
      "weighted avg       0.79      0.83      0.81      8195\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8082811865867747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.84      0.79      2178\n",
      "      neutro       0.26      0.06      0.09       711\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.83      8195\n",
      "   macro avg       0.63      0.61      0.60      8195\n",
      "weighted avg       0.80      0.83      0.81      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(CountVectorizer, ngram=(1,1), nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7604942606801933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.66      0.71      2178\n",
      "      neutro       0.29      0.02      0.03       712\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8196\n",
      "   macro avg       0.62      0.54      0.54      8196\n",
      "weighted avg       0.75      0.80      0.76      8196\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7687174574326897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.69      0.73      2178\n",
      "      neutro       0.29      0.01      0.03       712\n",
      "    positivo       0.82      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8196\n",
      "   macro avg       0.63      0.55      0.55      8196\n",
      "weighted avg       0.76      0.81      0.77      8196\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7730275831930157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.69      0.74      2178\n",
      "      neutro       0.50      0.03      0.05       711\n",
      "    positivo       0.82      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.70      0.56      0.56      8195\n",
      "weighted avg       0.78      0.81      0.77      8195\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7682939818545679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.69      0.73      2178\n",
      "      neutro       0.33      0.01      0.02       711\n",
      "    positivo       0.82      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.64      0.55      0.55      8195\n",
      "weighted avg       0.76      0.81      0.77      8195\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.763327302769285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.67      0.72      2178\n",
      "      neutro       0.16      0.01      0.02       711\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.58      0.55      0.54      8195\n",
      "weighted avg       0.75      0.80      0.76      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(CountVectorizer, ngram=(2,2), nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7562545619784365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.64      0.70      2178\n",
      "      neutro       0.31      0.02      0.03       712\n",
      "    positivo       0.80      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8196\n",
      "   macro avg       0.63      0.54      0.54      8196\n",
      "weighted avg       0.75      0.80      0.76      8196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7638448941495983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.67      0.72      2178\n",
      "      neutro       0.31      0.01      0.02       712\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8196\n",
      "   macro avg       0.63      0.55      0.54      8196\n",
      "weighted avg       0.76      0.80      0.76      8196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7640853153310843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.67      0.72      2178\n",
      "      neutro       0.32      0.01      0.02       711\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.64      0.55      0.54      8195\n",
      "weighted avg       0.76      0.80      0.76      8195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7617759109680996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.78      0.66      0.72      2178\n",
      "      neutro       0.42      0.01      0.02       711\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.67      0.55      0.54      8195\n",
      "weighted avg       0.77      0.80      0.76      8195\n",
      "\n",
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7587756540102649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.66      0.71      2178\n",
      "      neutro       0.18      0.01      0.02       711\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.59      0.54      0.53      8195\n",
      "weighted avg       0.74      0.80      0.76      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(CountVectorizer, ngram=(2,3), nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para todos os testes de n-grams utilizando o CountVectorizer obtivemos erros de convergência. Além disso, as métricas precision (presicão), recall (revocação) e f1-score não foram muito animadoras. Então vamos testar um método mais complexo onde leva em consideração a frequência das palavras e atribui um pesos para as mesmas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor TF-IDF (Term Frequency-Inverse Document Frequency), é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico.  O TF-IDF irá contar a frequência das palavras e atribui pesos as mesmas, ponderando-as em todo o dataset. Se uma palavra aparece muitas vezes, ela perde o poder de diferenciação, logo, possuirá um peso menor.\n",
    "\n",
    "\n",
    "$$TF=\\frac{\\text{Frequency of a word in the document}}{\\text{Total words in the document}}$$\n",
    "\n",
    "$$IDF = \\log\\left({\\frac{\\text{Total number of docs}}{\\text{Number of docs containing the words}}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos que estávamos utilizando até agora não gera um valor que preserve a sequência de palavras. O N-grams considera essencialmente uma sequência de palavras que aparecem na mesma \"janela\" ao mesmo tempo. Iremos testar modelos que com a utilização de N-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8094779032328606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.85      0.80      2178\n",
      "      neutro       0.37      0.04      0.07       712\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.67      0.61      0.59      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8138966260046941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2178\n",
      "      neutro       0.34      0.04      0.07       712\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.60      8196\n",
      "weighted avg       0.81      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8101244733499022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.74      0.86      0.80      2178\n",
      "      neutro       0.39      0.05      0.09       711\n",
      "    positivo       0.89      0.93      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8195\n",
      "   macro avg       0.67      0.62      0.60      8195\n",
      "weighted avg       0.81      0.84      0.81      8195\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8105479454267487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.85      0.80      2178\n",
      "      neutro       0.34      0.05      0.09       711\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8195\n",
      "   macro avg       0.66      0.61      0.60      8195\n",
      "weighted avg       0.80      0.84      0.81      8195\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.807414910978316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.74      0.86      0.79      2178\n",
      "      neutro       0.28      0.05      0.08       711\n",
      "    positivo       0.89      0.93      0.91      5306\n",
      "\n",
      "    accuracy                           0.83      8195\n",
      "   macro avg       0.64      0.61      0.60      8195\n",
      "weighted avg       0.80      0.83      0.81      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(TfidfVectorizer, ngram=(1,1), nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7671277973494347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.70      0.73      2178\n",
      "      neutro       0.39      0.01      0.02       712\n",
      "    positivo       0.82      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8196\n",
      "   macro avg       0.66      0.55      0.54      8196\n",
      "weighted avg       0.77      0.81      0.77      8196\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7730944971690533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.72      0.74      2178\n",
      "      neutro       0.44      0.01      0.02       712\n",
      "    positivo       0.83      0.96      0.89      5306\n",
      "\n",
      "    accuracy                           0.81      8196\n",
      "   macro avg       0.68      0.56      0.55      8196\n",
      "weighted avg       0.78      0.81      0.77      8196\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7731951377091065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.72      0.74      2178\n",
      "      neutro       0.44      0.01      0.02       711\n",
      "    positivo       0.83      0.95      0.89      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.68      0.56      0.55      8195\n",
      "weighted avg       0.78      0.81      0.77      8195\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7711748292338318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.72      0.74      2178\n",
      "      neutro       0.55      0.01      0.02       711\n",
      "    positivo       0.83      0.95      0.89      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.71      0.56      0.55      8195\n",
      "weighted avg       0.78      0.81      0.77      8195\n",
      "\n",
      "Score para n-grams (2, 2)\n",
      "f1_score: 0.7682788354720422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.71      0.73      2178\n",
      "      neutro       0.18      0.00      0.01       711\n",
      "    positivo       0.83      0.95      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.59      0.56      0.54      8195\n",
      "weighted avg       0.75      0.81      0.77      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(TfidfVectorizer, ngram=(2, 2), nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7621023947165763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.68      0.72      2178\n",
      "      neutro       0.39      0.01      0.02       712\n",
      "    positivo       0.81      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8196\n",
      "   macro avg       0.66      0.55      0.54      8196\n",
      "weighted avg       0.76      0.80      0.76      8196\n",
      "\n",
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7678997903656416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.70      0.73      2178\n",
      "      neutro       0.56      0.01      0.01       712\n",
      "    positivo       0.82      0.96      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8196\n",
      "   macro avg       0.71      0.56      0.54      8196\n",
      "weighted avg       0.78      0.81      0.77      8196\n",
      "\n",
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7674576555812515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.70      0.73      2178\n",
      "      neutro       0.64      0.01      0.02       711\n",
      "    positivo       0.82      0.95      0.88      5306\n",
      "\n",
      "    accuracy                           0.81      8195\n",
      "   macro avg       0.74      0.56      0.55      8195\n",
      "weighted avg       0.79      0.81      0.77      8195\n",
      "\n",
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7639291672202315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.70      0.73      2178\n",
      "      neutro       0.44      0.01      0.01       711\n",
      "    positivo       0.82      0.95      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.67      0.55      0.54      8195\n",
      "weighted avg       0.77      0.80      0.76      8195\n",
      "\n",
      "Score para n-grams (2, 3)\n",
      "f1_score: 0.7618716072338343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.69      0.72      2178\n",
      "      neutro       0.13      0.00      0.01       711\n",
      "    positivo       0.82      0.95      0.88      5306\n",
      "\n",
      "    accuracy                           0.80      8195\n",
      "   macro avg       0.57      0.55      0.54      8195\n",
      "weighted avg       0.74      0.80      0.76      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(TfidfVectorizer, ngram=(2, 3), nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentre os valores de n-grams testados anteriormente para o TfidfVectorizer, o único que será testado será Uni-gram (1,1), pois foi o que obtive o melhor f1-score para classificação da classe 'neutro'. Os demais n-grams até obtiveram valores interessante de precisão (precision), mas a revocação (recall) foram 0 ou 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2. Analisando o max_features, min_df e max_df para Unigrams (ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_features: O hiperparâmetro considera apenas as principais features (palavras ou conjunto de palavras) ordenados por frequência de termo em todo o corpus.\n",
    "- min_df: O hiperparâmetro define um limite para ignorar os termos que tenham uma frequência de documento estritamente inferior ao limite fornecido.\n",
    "- max_df: O hiperparâmetro define um limite para ignorar os termos que têm uma frequência de documento estritamente superior ao limite determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "# Dfinido X e y \n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer()))\n",
    "    ])\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para verificar a acuracia dos melhores valores de hiperparamentros\n",
    "def hiperparamentros_tfidfVectorizer(X_processed, y, max_features, min_df, max_df, ngram=(1, 1)):\n",
    "    col=['max_features', 'min_df', 'max_df', 'f1_score']\n",
    "    list = []\n",
    "    scorer = make_scorer(f1_score, average = 'weighted')\n",
    "    for maxfeatures in max_features:\n",
    "        for mindf in min_df:\n",
    "            for maxdf in max_df:\n",
    "                vectorizer = TfidfVectorizer(max_features=maxfeatures, min_df=mindf, max_df=maxdf, ngram_range=ngram)\n",
    "\n",
    "                X = vectorizer.fit_transform(X_processed)\n",
    "\n",
    "                #Criação do modelo\n",
    "                regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42)\n",
    "\n",
    "                #aplicando a validação cruzada\n",
    "                score = np.mean(cross_val_score(regressao_logistica, X, y, scoring=scorer, cv=StratifiedKFold(n_splits=5)))\n",
    "                list.append([maxfeatures, mindf, maxdf, score])\n",
    "    return pd.DataFrame(list, columns=col).sort_values('f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.713766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  min_df  max_df  f1_score\n",
       "0           300    0.05    0.80  0.757767\n",
       "1           300    0.05    0.90  0.757767\n",
       "2           300    0.05    0.95  0.757767\n",
       "3           500    0.05    0.95  0.757767\n",
       "4           500    0.05    0.90  0.757767\n",
       "5           500    0.05    0.80  0.757767\n",
       "6           400    0.05    0.80  0.757767\n",
       "7           400    0.05    0.90  0.757767\n",
       "8           400    0.05    0.95  0.757767\n",
       "9           500    0.20    0.95  0.713766"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [300, 400, 500]\n",
    "min_df = [0.05, 0.2, 0.3]\n",
    "max_df = [0.8, 0.9, 0.95]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(X_processed, y, max_features, min_df, max_df)\n",
    "df_score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que para os dez maiores valores de score calculado são para o min_df igual a 0.05, independente das variações dos outros hiperparâmetros. Então, vamos reajustar o valor de min_df e calcular novamente os valores de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  min_df  max_df  f1_score\n",
       "0           500   0.001     0.7  0.814828\n",
       "1           500   0.000     0.9  0.814828\n",
       "2           500   0.000     0.7  0.814828\n",
       "3           500   0.001     0.9  0.814828\n",
       "4           500   0.001     0.8  0.814828\n",
       "5           500   0.000     0.8  0.814828\n",
       "6           400   0.000     0.9  0.812673\n",
       "7           400   0.000     0.8  0.812673\n",
       "8           400   0.000     0.7  0.812673\n",
       "9           400   0.001     0.9  0.812613"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [300, 400, 500]\n",
    "min_df = [0, 0.001, 0.005, 0.01, 0.05]\n",
    "max_df = [0.7, 0.8, 0.9]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(X_processed, y, max_features, min_df, max_df)\n",
    "df_score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, é possível visualizar as seguintes afirmações:\n",
    "- Quanto menor o valor min_df melhor é acuracia do modelo;\n",
    "- Quanto maior o valor max_features melhor é acuracia do modelo (podendo causar overfitting);\n",
    "- O valor de max_df não contribuiu para melhora da acurácia para esse conjunto de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.815744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.815744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.815744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.814828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features  min_df  max_df  f1_score\n",
       "0            600   0.000     0.9  0.815768\n",
       "1            600   0.000     0.8  0.815768\n",
       "2            600   0.000     0.7  0.815768\n",
       "3            600   0.001     0.9  0.815744\n",
       "4            600   0.001     0.8  0.815744\n",
       "5            600   0.001     0.7  0.815744\n",
       "6            500   0.001     0.8  0.814828\n",
       "7            500   0.001     0.9  0.814828\n",
       "8            500   0.000     0.7  0.814828\n",
       "9            500   0.000     0.8  0.814828\n",
       "10           500   0.000     0.9  0.814828\n",
       "11           500   0.001     0.7  0.814828\n",
       "12           400   0.000     0.8  0.812673\n",
       "13           400   0.000     0.7  0.812673\n",
       "14           400   0.000     0.9  0.812673\n",
       "15           400   0.001     0.9  0.812613\n",
       "16           400   0.001     0.8  0.812613\n",
       "17           400   0.001     0.7  0.812613\n",
       "18           400   0.005     0.9  0.806506\n",
       "19           500   0.005     0.7  0.806506"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [400, 500, 600]\n",
    "min_df = [0, 0.001, 0.005]\n",
    "max_df = [0.7, 0.8, 0.9]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(X_processed, y, max_features, min_df, max_df)\n",
    "df_score.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentar o valor de features para melhora do modelo de classificação não resultou em grande melhora da acurácia (score) do modelo, mas em contrapartida aumento sua complexidade e podendo causar overfitting. Então vamos escolher o melhor conjunto de hiperparâmetros para o max_features igual a 400. Logo, vamos escolher o maior valor de min_df e o menor valor de max_df para tentar tornar o modelo mais genérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.806506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features  min_df  max_df  f1_score\n",
       "12           400   0.000     0.8  0.812673\n",
       "13           400   0.000     0.7  0.812673\n",
       "14           400   0.000     0.9  0.812673\n",
       "15           400   0.001     0.9  0.812613\n",
       "16           400   0.001     0.8  0.812613\n",
       "17           400   0.001     0.7  0.812613\n",
       "18           400   0.005     0.9  0.806506\n",
       "22           400   0.005     0.8  0.806506\n",
       "23           400   0.005     0.7  0.806506"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[df_score['max_features'] == 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores de hiperparâmetros selecionados:\n",
    "- max_features = 400\n",
    "- min_df = 0.001\n",
    "- max_df = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8094779032328606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.85      0.80      2178\n",
      "      neutro       0.37      0.04      0.07       712\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.67      0.61      0.59      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8138966260046941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2178\n",
      "      neutro       0.34      0.04      0.07       712\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.60      8196\n",
      "weighted avg       0.81      0.84      0.81      8196\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8101244733499022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.74      0.86      0.80      2178\n",
      "      neutro       0.39      0.05      0.09       711\n",
      "    positivo       0.89      0.93      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8195\n",
      "   macro avg       0.67      0.62      0.60      8195\n",
      "weighted avg       0.81      0.84      0.81      8195\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.8105479454267487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.85      0.80      2178\n",
      "      neutro       0.34      0.05      0.09       711\n",
      "    positivo       0.89      0.94      0.91      5306\n",
      "\n",
      "    accuracy                           0.84      8195\n",
      "   macro avg       0.66      0.61      0.60      8195\n",
      "weighted avg       0.80      0.84      0.81      8195\n",
      "\n",
      "Score para n-grams (1, 1)\n",
      "f1_score: 0.807414910978316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.74      0.86      0.79      2178\n",
      "      neutro       0.28      0.05      0.08       711\n",
      "    positivo       0.89      0.93      0.91      5306\n",
      "\n",
      "    accuracy                           0.83      8195\n",
      "   macro avg       0.64      0.61      0.60      8195\n",
      "weighted avg       0.80      0.83      0.81      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report_ngrams(TfidfVectorizer, ngram=(1,1), nsplits=5, maxfeatures=400, mindf=0.001, maxdf=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1. Implementação Word2Vec pela biblioteca spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca spaCy possui modelos e pipelines treinados para serem utilizados em projetos de NLP. Será utilizado o modelo 'pt_core_news_sm'. A seguir temos uma simples demostração do funcionamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Esta', 'PRON'), ('é', 'AUX'), ('uma', 'DET'), ('frase', 'NOUN'), ('.', 'PUNCT')]\n",
      "[ 1.6862637   1.0966642  -0.44830102  1.2407768   1.2119696   0.4967288\n",
      "  1.1355568  -0.3789686  -0.23921096 -1.0028999   0.01694105  1.0304904\n",
      " -0.77945006 -1.8455906   0.14623375 -1.5098034   0.09465428  0.23753071\n",
      "  0.7262373  -3.4491882  -0.06529514 -0.35115677  0.25457078  0.97570646\n",
      "  1.3779566  -0.07742429  2.3602567   1.3939953  -1.0734911   0.51703084\n",
      " -0.06598546 -0.13703804 -1.6283951  -0.24659435 -2.7218637  -1.726352\n",
      "  0.7910467  -0.3519574  -1.2363064   0.21610522  1.2061622  -1.2713051\n",
      "  2.08051     2.0840862  -3.1898916  -0.1673429   1.206226    4.5296965\n",
      " -3.36494     0.5160467   0.7298645  -2.5763297  -1.0656779  -1.3060184\n",
      " -0.67010766 -2.3228176  -0.8842122   0.43415537  1.3984268   1.0577457\n",
      " -0.5068926   0.4359377  -1.6620098   0.45011562 -1.9427035   2.2010276\n",
      "  0.07313128  1.7914689  -0.78537834 -0.7929416   0.62613255  4.374768\n",
      " -1.5901229   0.80564517 -1.8765942  -2.4415004   0.43080473  0.47225484\n",
      " -1.5491395  -0.67420495 -2.8946824   0.18531652  0.01723059 -0.20907629\n",
      "  2.0791006   2.7983825   0.17668304  1.6146924  -2.555139    2.8869371\n",
      " -0.45493808  1.3831619   3.022241    0.5266367   1.0223396   0.5301677 ]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "doc = nlp(\"Esta é uma frase.\")\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "print(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer()))\n",
    "])\n",
    "\n",
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "X_processed_w2v = [nlp(review).vector for review in X_processed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformando a lista X_processed_w2v em um dataframe\n",
    "df_X_processed_w2v = pd.DataFrame(list(map(np.ravel, X_processed_w2v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando os review_score \n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "# Removendo os valores NaN gerados no processo de trasformação dos dados \n",
    "df_ml = pd.concat([df_X_processed_w2v, score], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Word2Vec\n",
      "f1_score: 0.7391923520471352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.66      0.70      0.68      3627\n",
      "      neutro       0.20      0.00      0.01      1182\n",
      "    positivo       0.82      0.91      0.86      8797\n",
      "\n",
      "    accuracy                           0.77     13606\n",
      "   macro avg       0.56      0.54      0.52     13606\n",
      "weighted avg       0.72      0.77      0.74     13606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Word2Vec\n",
      "f1_score: 0.7423332638481633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.68      0.70      0.69      3626\n",
      "      neutro       0.24      0.00      0.01      1183\n",
      "    positivo       0.82      0.92      0.86      8797\n",
      "\n",
      "    accuracy                           0.78     13606\n",
      "   macro avg       0.58      0.54      0.52     13606\n",
      "weighted avg       0.73      0.78      0.74     13606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Word2Vec\n",
      "f1_score: 0.7390485884020849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.66      0.70      0.68      3626\n",
      "      neutro       0.25      0.01      0.01      1182\n",
      "    positivo       0.82      0.91      0.86      8797\n",
      "\n",
      "    accuracy                           0.77     13605\n",
      "   macro avg       0.58      0.54      0.52     13605\n",
      "weighted avg       0.73      0.77      0.74     13605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separando o dataset em X e Y\n",
    "X = df_ml.iloc[:, :-1].values\n",
    "y = df_ml.iloc[:,-1].values\n",
    "\n",
    "# Cria 3 partições com os dados de disponíveis\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(df_ml.iloc[:, :-1], df_ml.iloc[:,-1])\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Criação do modelo\n",
    "    regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42, max_iter=200)\n",
    "\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, regressao_logistica.predict(X_test)\n",
    "    score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Score Word2Vec')\n",
    "    print(f'f1_score: {score}')\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2. Implementação Word2Vec pela biblioteca nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca nltk contem a classe Word2Vec que é um algoritmo para construir representações vetoriais de palavras, também conhecido como word embeddings. O vetor para cada palavra é uma descrição semântica de como essa palavra é usada no contexto, portanto, duas palavras que são usadas de maneira semelhante no texto terão representações vetoriais semelhantes. Depois de mapear palavras no espaço vetorial, você pode usar a matemática vetorial para encontrar palavras que tenham semântica semelhante. Para implementar o Word2Vec neste projeto, iremos treinar um modelo a partir da própria base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['receb', 'bem', 'ant', 'praz', 'estipul']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_separado_por_palavra = list()\n",
    "for item in  X_processed:\n",
    "    x_separado_por_palavra.append(word_tokenize(item))\n",
    "\n",
    "# Trasfoamando cada review em lista composta por todas as palavras\n",
    "x_separado_por_palavra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brothers\\AppData\\Local\\Temp/ipykernel_7228/3021681431.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_w2v = np.array(x_separado_por_palavra)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list(['receb', 'bem', 'ant', 'praz', 'estipul']),\n",
       "       list(['parab', 'loj', 'lannist', 'ador', 'compr', 'internet', 'segur', 'pra', 'parab', 'tod', 'feliz', 'pasco'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trasformando a lista de palavras em um array de palavras\n",
    "X_w2v = np.array(x_separado_por_palavra)\n",
    "X_w2v[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando os Embeddings com a Coleção\n",
    "# sg=1 -- Skip Gram\n",
    "model = Word2Vec(X_w2v, vector_size=300, window=5, sg=1, workers=4)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index_to_key, model.wv.vectors)}\n",
    "word_vectors = model.wv\n",
    "len(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "    ('w2v', E2V_IDF(w2v))\n",
    "])\n",
    "\n",
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.75199600e-03,  1.86525151e-01,  3.83282751e-02,  8.33293274e-02,\n",
       "       -6.05972251e-03, -1.31283864e-01,  7.21414313e-02,  3.08452785e-01,\n",
       "        1.39897084e-02, -2.53857626e-03, -9.88215767e-03, -1.19019739e-01,\n",
       "        4.32758071e-02, -1.93288624e-02, -8.33064616e-02, -4.78607975e-02,\n",
       "        3.56259197e-02,  2.24428307e-02,  9.70229581e-02, -2.51476299e-02,\n",
       "       -1.67030945e-01, -1.99590269e-02,  8.15033391e-02,  1.07512206e-01,\n",
       "        1.54096887e-01,  4.03406434e-02, -1.77595034e-01,  7.23470375e-02,\n",
       "       -6.42824918e-02, -1.50666609e-01,  2.05498617e-02, -1.12472296e-01,\n",
       "        3.89049053e-02,  5.31133041e-02, -1.12498943e-02,  3.08047533e-02,\n",
       "        1.25670940e-01, -1.24974258e-01, -7.52034187e-02,  2.23629754e-02,\n",
       "        1.09653398e-02,  2.98187118e-02,  1.32519193e-02,  6.42805966e-03,\n",
       "        1.07772395e-01,  1.13337703e-01, -4.08071466e-02,  6.76041795e-03,\n",
       "        2.81910971e-02,  6.11983426e-02,  5.21695577e-02,  5.22530675e-02,\n",
       "       -2.49724016e-02,  4.19023493e-03, -4.53125983e-02,  1.30895346e-01,\n",
       "       -2.13409383e-02,  4.76530232e-02,  1.97360665e-02, -3.51955742e-02,\n",
       "       -6.97193742e-02, -6.81955665e-02, -1.44143244e-02,  1.21150352e-02,\n",
       "        5.76504469e-02, -7.50764832e-02,  2.72955894e-02,  3.14894468e-02,\n",
       "       -6.17509857e-02, -7.03185871e-02, -5.12928935e-03,  4.44957800e-02,\n",
       "        1.54143646e-01, -1.08834051e-01,  1.98568236e-02,  7.92725533e-02,\n",
       "       -6.61898851e-02,  9.60548148e-02, -6.41732812e-02,  1.01147838e-01,\n",
       "       -5.50030470e-02, -1.32819310e-01,  1.28239254e-02,  2.53648072e-01,\n",
       "        4.31131274e-02,  2.41951570e-02, -1.02751367e-01, -1.80268958e-02,\n",
       "        7.73698837e-02,  2.84287818e-02,  1.37576267e-01, -8.62850845e-02,\n",
       "       -4.83501777e-02, -5.10698296e-02,  1.07609935e-01,  1.22487277e-01,\n",
       "        1.95986211e-01, -9.82277915e-02, -2.62585748e-02, -4.76990547e-03,\n",
       "       -2.67689750e-02, -6.94093574e-03,  1.01555280e-01, -3.30359153e-02,\n",
       "        1.24979354e-01, -4.39781807e-02, -2.42795106e-02,  2.43073218e-02,\n",
       "       -1.38862669e-01,  9.16208699e-02, -1.32427678e-01, -6.51232526e-02,\n",
       "       -4.26138677e-02,  6.65116385e-02,  2.62723882e-02,  1.31183729e-01,\n",
       "        1.16796382e-02, -4.19523269e-02,  1.95570096e-01, -1.19212009e-01,\n",
       "        8.15315470e-02,  6.50172979e-02,  1.40831724e-01,  2.68524420e-02,\n",
       "       -6.86008781e-02,  5.94843999e-02, -6.65576430e-03, -2.64435470e-01,\n",
       "       -6.58860372e-04,  9.88814980e-03,  8.54982510e-02,  1.04773514e-01,\n",
       "        1.20497063e-01, -1.80943340e-01,  1.15741998e-01,  3.12162451e-02,\n",
       "       -8.63757432e-02, -8.17255676e-02, -1.29681751e-01, -1.52211785e-01,\n",
       "       -1.47003070e-01, -1.78905234e-01, -9.19570997e-02,  1.10614970e-01,\n",
       "        3.92955095e-02, -9.97402444e-02, -1.75450966e-01, -3.08102230e-03,\n",
       "        1.18188545e-01, -9.50718112e-03,  1.72382966e-02, -1.61042556e-01,\n",
       "       -1.32010616e-02, -6.49996568e-03,  6.04778975e-02,  2.11640485e-02,\n",
       "       -1.15968682e-01, -1.17452748e-01, -1.54401700e-03,  1.34753481e-01,\n",
       "        6.88707754e-02,  1.21012807e-01, -1.82989597e-01,  1.45584956e-01,\n",
       "       -1.45486534e-01,  9.38341953e-03,  2.15943363e-02,  6.32911399e-02,\n",
       "        7.88926035e-02,  2.12286472e-01,  6.08343678e-03,  1.50173128e-01,\n",
       "        5.93208894e-02,  1.13404552e-02, -2.90028527e-02, -2.27815192e-02,\n",
       "       -6.19104244e-02, -8.37814510e-02,  4.63551879e-02, -5.24359830e-02,\n",
       "       -1.37303293e-01,  5.07828966e-02, -4.52718176e-02, -4.01136726e-02,\n",
       "        1.20017594e-02, -1.36694424e-02,  1.25604272e-01,  1.53929725e-01,\n",
       "        3.60906683e-02, -1.46615177e-01, -1.74892899e-02,  6.46545216e-02,\n",
       "       -7.86997750e-02,  1.13156602e-01, -3.68011279e-05, -1.76747188e-01,\n",
       "        7.72111341e-02, -6.87052161e-02,  5.30958883e-02, -3.26944366e-02,\n",
       "       -1.38940990e-01,  1.10429406e-01,  4.73242439e-02, -4.87126932e-02,\n",
       "       -2.08688546e-02, -3.84710878e-02, -4.46476564e-02,  1.02588817e-01,\n",
       "       -3.02138198e-02, -1.05420224e-01, -8.34813714e-02, -1.70134678e-01,\n",
       "       -7.53458738e-02, -8.07522610e-02, -2.29121987e-02, -2.46992394e-01,\n",
       "       -6.67086616e-02, -2.71776915e-01, -1.37118652e-01, -6.89421222e-02,\n",
       "        4.52789813e-02, -5.83180822e-02, -4.73992601e-02, -7.20362738e-02,\n",
       "       -5.95669039e-02, -6.64282143e-02,  5.16803488e-02, -2.70710811e-02,\n",
       "       -5.16633131e-02,  6.53463677e-02,  1.58105027e-02, -4.76984605e-02,\n",
       "       -1.21950604e-01,  4.21959646e-02,  2.25118245e-03,  6.33368343e-02,\n",
       "        2.25531291e-02,  1.59507766e-02,  7.03087426e-04, -2.08020985e-01,\n",
       "        6.26414418e-02, -1.27619877e-01, -6.84143677e-02,  5.44042699e-02,\n",
       "        4.35204338e-03, -7.63165653e-02, -1.21526774e-02,  4.27258341e-03,\n",
       "        1.13427946e-02,  1.59038320e-01, -2.97292881e-02,  6.23219125e-02,\n",
       "        1.71983782e-02,  5.03571797e-03, -1.91281378e-01, -4.06144746e-02,\n",
       "        1.87104270e-01,  8.94562677e-02, -2.08683297e-01, -2.80323047e-02,\n",
       "        1.47054762e-01,  1.03910141e-01, -3.91116068e-02, -1.57580957e-01,\n",
       "       -3.60715799e-02, -4.65259701e-02,  4.93790060e-02,  9.13617387e-02,\n",
       "       -8.55163634e-02, -8.72103646e-02, -1.49625793e-01,  1.80730764e-02,\n",
       "        1.26643881e-01,  3.12631838e-02,  2.42757887e-01,  7.72037432e-02,\n",
       "        1.46231711e-01,  8.86155218e-02, -9.23115015e-02,  9.51281562e-02,\n",
       "        1.60651788e-01,  6.63433746e-02,  1.20083503e-02,  6.64604902e-02,\n",
       "        4.70860861e-03, -3.10745789e-04, -2.95535643e-02,  5.28730303e-02,\n",
       "        6.51698560e-02,  1.44976318e-01,  1.44898593e-02,  1.98558435e-01,\n",
       "        1.20403141e-01,  5.45027964e-02,  2.59461761e-01,  2.07625061e-01,\n",
       "        2.61444338e-02, -1.33831993e-01,  6.33428767e-02, -1.10816015e-02])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representação de um review (conjunto de palavras) a partir do modelo word2vec\n",
    "X_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para W2V_AVG\n",
      "f1_score: 0.6377204025022661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.60      0.34      0.43      2178\n",
      "      neutro       0.00      0.00      0.00       712\n",
      "    positivo       0.71      0.93      0.81      5306\n",
      "\n",
      "    accuracy                           0.69      8196\n",
      "   macro avg       0.44      0.42      0.41      8196\n",
      "weighted avg       0.62      0.69      0.64      8196\n",
      "\n",
      "Score para W2V_AVG\n",
      "f1_score: 0.6383020488751269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.60      0.33      0.43      2178\n",
      "      neutro       0.00      0.00      0.00       712\n",
      "    positivo       0.71      0.94      0.81      5306\n",
      "\n",
      "    accuracy                           0.70      8196\n",
      "   macro avg       0.44      0.42      0.41      8196\n",
      "weighted avg       0.62      0.70      0.64      8196\n",
      "\n",
      "Score para W2V_AVG\n",
      "f1_score: 0.6424177470207232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.61      0.34      0.44      2178\n",
      "      neutro       0.00      0.00      0.00       711\n",
      "    positivo       0.72      0.94      0.81      5306\n",
      "\n",
      "    accuracy                           0.70      8195\n",
      "   macro avg       0.44      0.43      0.42      8195\n",
      "weighted avg       0.62      0.70      0.64      8195\n",
      "\n",
      "Score para W2V_AVG\n",
      "f1_score: 0.6425486006567488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.60      0.35      0.44      2178\n",
      "      neutro       0.00      0.00      0.00       711\n",
      "    positivo       0.72      0.93      0.81      5306\n",
      "\n",
      "    accuracy                           0.70      8195\n",
      "   macro avg       0.44      0.43      0.42      8195\n",
      "weighted avg       0.62      0.70      0.64      8195\n",
      "\n",
      "Score para W2V_AVG\n",
      "f1_score: 0.640641982995776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.61      0.34      0.44      2178\n",
      "      neutro       0.00      0.00      0.00       711\n",
      "    positivo       0.71      0.94      0.81      5306\n",
      "\n",
      "    accuracy                           0.70      8195\n",
      "   macro avg       0.44      0.43      0.42      8195\n",
      "weighted avg       0.62      0.70      0.64      8195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cria 3 partições com os dados de disponíveis\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X_processed, y)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X_processed, y):\n",
    "    X_train, X_test = X_processed[train_index], X_processed[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Criação do modelo\n",
    "    regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42, max_iter=200)\n",
    "\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, regressao_logistica.predict(X_test)\n",
    "    score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Score para W2V_AVG')\n",
    "    print(f'f1_score: {score}')\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelos de Classificação de Sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns algoritmos de regressão também podem ser utilizados para classificação (e vice-versa). A Regressão Logística (também chamada de Regressão Logit) é comumente utilizada para estimar a probabilidade de uma instância pertencer a uma determinada classe. Assim como um modelo de Regressão Linear, um modelo de Regressão Logística calcula uma soma ponderada das características de entrada (mais um termo de polarização), mas, em vez de gerar o resultado diretamente como o modelo de Regressão Linear, gera a logística desse resultado.\n",
    "\n",
    "O modelo de Regressão Logística pode ser generalizado para suportar múltiplas classes diretamente sem a necessidade de treinar e combinar vários classificadores binários. Isso é chamado Regressão Softmax, ou Regressão Logística Multinomial. A ideia é bem simples: quando dada uma instância x, o modelo de Regressão Softmax primeiro calcula uma pontuação sk(x) para cada classe k, então estima a probabilidade de cada classe aplicando a função softmax (também chamada exponencial normalizada) às pontuações.\n",
    "\n",
    "Uma vez calculada a pontuação de cada classe para a instância x, você pode estimar a probabilidade Pk de a instância pertencer à classe k ao executar as pontuações através da função softmax: ela calcula a exponencial de cada pontuação e a normaliza (dividindo pela soma de todas as exponenciais). Assim como o classificador de Regressão Logística, o classificador de Regressão Softmax prevê a classe com a maior probabilidade estimada (que é simplesmente a classe com a maior pontuação)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1. Recalculando a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos recalcular o score para o mesmo modelo que foi calculado a baseline, ou seja, iremos utilizar os mesmo hiperpâmetros para a LogisticRegression, mas iremos utilizar a base de dados tratada pelo Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo todas as trafomações regex para serem aplicadas ao pipeline\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, min_df=0.001, max_df=0.7) \n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "    ('text_features', ExtracaoFeatures(vectorizer))\n",
    "])\n",
    "\n",
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "# Dfinido X e y \n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a função cross_val_score() para avaliar o modelo LogisticRegression com a utilização da validação cruzada K-fold com três partes. Lembre-se de que a validação cruzada K-fold significa dividir o conjunto de treinamento em K-folds (neste caso, três), prever e avaliar as previsões em cada conjunto utilizando um modelo treinado em conjuntos restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:[0.84017864 0.84318032 0.84405886]\n",
      "Média: 0.8424726065841814\n",
      "Desvio Padrão: 0.001661260943955625\n"
     ]
    }
   ],
   "source": [
    "regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "scores = cross_val_score(regressao_logistica, X_processed, y, cv=3, scoring=\"accuracy\")\n",
    "print(f'Scores:{np.sort(scores)}')\n",
    "print(f'Média: {scores.mean()}')\n",
    "print(f'Desvio Padrão: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os valores dos scores obtido e com os valores da baseline antes do tratamento dos dados é possível perceber um ganho de 4.7% na acurácia do modelo utilizando os mesmos hiperparâmetros para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.84      0.79      2151\n",
      "      neutro       0.34      0.05      0.08       730\n",
      "    positivo       0.88      0.94      0.91      5315\n",
      "\n",
      "    accuracy                           0.83      8196\n",
      "   macro avg       0.66      0.61      0.59      8196\n",
      "weighted avg       0.80      0.83      0.80      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CR = classification_report(y_test, y_pred)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as métricas para a classe \"neutro\" é possível confirmar de forma numérica o péssimo resultado de classificação para classe. As classes \"negativo\" e \"possitivo\" possui ótimas métricas, enquanto a classe \"neutro\" possui apenas 36% de precisão e 6% de revogação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2. Otimizando os hiperparamentors do modelo de LogisticRegression (BayesSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe BayesSearchCV é uma otimização Bayesiana sobre hiperparâmetros. Os parâmetros do estimador usados ​​para aplicar esses métodos são otimizados por pesquisa de validação cruzada sobre configurações de parâmetros. Ao contrário do GridSearchCV, nem todos os valores de parâmetro são testados, mas um número fixo de configurações de parâmetro é amostrado das distribuições especificadas. O número de configurações de parâmetro que são tentadas é dado por n_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros: \n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "OrderedDict([('C', 0.5151918020836844), ('class_weight', 'balanced'), ('max_iter', 100), ('penalty', 'l1'), ('solver', 'liblinear')])\n",
      "f1_score (weighted): 0.8276859175154488\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.85      0.80      2151\n",
      "      neutro       0.31      0.27      0.29       730\n",
      "    positivo       0.92      0.89      0.91      5315\n",
      "\n",
      "    accuracy                           0.83      8196\n",
      "   macro avg       0.66      0.67      0.66      8196\n",
      "weighted avg       0.82      0.83      0.82      8196\n",
      "\n",
      "Tempo de execução: 61.76109137535095min\n"
     ]
    }
   ],
   "source": [
    " # log-uniform: understand as search over p = exp(x) by varying x\n",
    "\n",
    "search_spaces=[{\n",
    "  'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "  'multi_class': Categorical(['multinomial']),\n",
    "  'penalty': Categorical(['l2', 'none']),\n",
    "  'solver': Categorical(['lbfgs', 'sag']),\n",
    "  'class_weight': Categorical(['balanced', None]),\n",
    "  'max_iter': Integer(100, 1000) \n",
    "}, {\n",
    "  'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "  'penalty': Categorical(['l1', 'l2']),\n",
    "  'solver': Categorical(['liblinear']),\n",
    "  'class_weight': Categorical(['balanced', None]),\n",
    "  'max_iter': Integer(100, 1000) \n",
    "}]\n",
    "n_iter = 40\n",
    "model = LogisticRegression()\n",
    "incial = time()\n",
    "print_score_BayesSearchCV(model, X_processed, y, search_spaces, n_iter)\n",
    "final = time()\n",
    "print(f'Tempo de execução: {(final - incial) / 60}min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. SVM (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma Máquina de Vetores de Suporte (SVM) é um modelo muito poderoso e versátil de Aprendizado de Máquina capaz de realizar classificações lineares ou não lineares, de regressão e até mesmo detecção de outliers. As SVM são particularmente adequadas para a classificação de conjuntos de dados complexos. Dentro da modulo SVM iremos utilizar a classe SVC (C-Support Vector Classification.), no qual o suporte multiclasse é tratado de acordo com um esquema de um contra um.\n",
    "\n",
    "Hiperparâmetro:\n",
    "- C: Parâmetro de regularização. Um valor menor de C leva a uma via mais larga, mas com mais violações das margens.\n",
    "- kernel: Especifica o tipo de kernel a ser usado no algoritmo. \n",
    "- coef0: controla o quanto o modelo é influenciado por polinômios de alto grau versus polinômios de baixo grau. Só é significativo em 'poli' e 'sigmóide'.\n",
    "- gamma: Coeficiente de kernel para 'rbf', 'poli' e 'sigmoid'.\n",
    "    - Se gamma='scale'(padrão) for passado, ele usará 1 / (n_features * X.var()) como valor de gama,\n",
    "    - Se 'auto', usa 1 / n_features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.819 (+/-0.010) for {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.678 (+/-0.023) for {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.89      0.81      2151\n",
      "      neutro       0.27      0.02      0.04       730\n",
      "    positivo       0.89      0.94      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.64      0.62      0.59      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [1.0],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': ['scale', 'auto'] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma primeira analise com o classificador SVC houve uma pequena melhora na classificação das classes 'negativo' e 'positivo', enquanto a classe 'neutro' piorou significativamente, se comparada com o melhor modelo de LogisticRegression. O custo computacional para o classificador SVC foi muito superior. A classe 'neutra' se manteve como a pior classe na classificação dos reveiws, se comparado com o modelo de LogisticRegression, teve uma queda de 0.09 em f1-score e 0.06 no recall. \n",
    "\n",
    "Iremos verificar o aumento do valor de 'C' e a definição do valor de 'gama' manualmente. O alto valor de C faz o classificador possuir menos violações na margem, mas fica com uma margem menor. Aumentar ‘gamma’ estreitará a curva em forma de sino, e como resultado cada raio de influência da instância será menor: mexer ao redor de instâncias individuais torna a fronteira de decisão mais irregular. Por outro lado, um pequeno valor de ‘gamma’ torna a curva em forma de sino mais ampla, de modo que as instâncias ficam com um maior raio de influência e o limite de decisão fica mais suave.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.807 (+/-0.003) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.580 (+/-0.014) for {'C': 1.0, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.003) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.586 (+/-0.012) for {'C': 100, 'gamma': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [1.0, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1, 10] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variação dos hiperparâmetros resultou em uma excelente melhora no modelo de classificação em todas as classes chegando a superar o melhor modelo de LogisticRegression. Em especial houve melhora na classe 'neutro', nas métricas recall e f1-score.\n",
    "\n",
    "Como o melhor modelo encontrado possui um valor alto de do hiperparâmetros 'C', vamos verificar se aumentando ainda mais seu valor melhora o resultado da classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 200, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.006) for {'C': 200, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.006) for {'C': 300, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.84      0.80      2151\n",
      "      neutro       0.25      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.83      8196\n",
      "   macro avg       0.63      0.62      0.62      8196\n",
      "weighted avg       0.80      0.83      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [200, 300],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O grande aumento do hiperparâmetro 'C' não resultou em melhora do modelo, mas resultou em um valor de f1-score bastante próximo do melhor modelo encontrodado. Então vamos verificar um valor de 'C' mais próximo de 100 (valor do melhor classificado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 125, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.005) for {'C': 125, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.004) for {'C': 125, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.005) for {'C': 175, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.004) for {'C': 175, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.86      0.81      2151\n",
      "      neutro       0.30      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.65      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [125, 175],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1, 1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.001) for {'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.002) for {'C': 112, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [110, 112],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados obtidos foram bastante similar com o modelo de parâmentros igual {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}. O valor de f1-score foi menor que 0.825 (+/-0.003), mas o desvio padrão foi menor (+/-0.001) para os três valores calculados para Cross-Validation.\n",
    "\n",
    "O melhor modelo para o SVC selecionado será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.824 (+/-0.003) for {'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n",
      "Tempo de execução: 46.78752770423889min\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [110],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "incial = time()\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)\n",
    "final = time()\n",
    "print(f'Tempo de execução: {(final - incial) / 60}min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros: \n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "OrderedDict([('C', 5.114312906246165), ('gamma', 0.7052207811078224), ('kernel', 'rbf')])\n",
      "f1_score (weighted): 0.8245544917624398\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.86      0.81      2151\n",
      "      neutro       0.28      0.08      0.13       730\n",
      "    positivo       0.90      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.64      0.63      0.62      8196\n",
      "weighted avg       0.80      0.84      0.82      8196\n",
      "\n",
      "Tempo de execução: 670.8822413841883min\n"
     ]
    }
   ],
   "source": [
    " # log-uniform: understand as search over p = exp(x) by varying x\n",
    "\n",
    "search_spaces=[{\n",
    "    'C': Real(1e-3, 1e+3, prior='log-uniform'),\n",
    "    'kernel' : Categorical(['rbf']),\n",
    "    'gamma': Real(0.1, 10, prior='log-uniform') \n",
    "}]\n",
    "\n",
    "model = SVC()\n",
    "n_iter = 50\n",
    "incial = time()\n",
    "print_score_BayesSearchCV(model, X_processed, y, search_spaces, n_iter)\n",
    "final = time()\n",
    "print(f'Tempo de execução: {(final - incial) / 60}min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12fb55c19b53ac09035d9d6bd41a050fcb0becbe4846579be579fa8f11e9abb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
